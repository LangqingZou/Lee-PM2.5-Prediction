{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11112235",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''只用PM2.5作为特征预测'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2d81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @File    : main.py\n",
    "# @Date    : 2021-8-6\n",
    "# @Author  : Langqing Zou\n",
    "# @Software: VS Code\n",
    "# @Python Version: python 3.6\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d4b390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--------------------Read data and Preprocessing--------------------'''  \n",
    "train_data = pd.read_csv(\"./train.csv\")\n",
    "temp = pd.read_csv(\"./train.csv\")\n",
    "del train_data[\"Date\"]\n",
    "del train_data[\"stations\"]\n",
    "column = train_data[\"observation\"].unique()\n",
    "\n",
    "# Try to have more train data:\n",
    "# Train data: 0-9,1-10,2-11.....; check it with 10,11,12 respectively\n",
    "features = 18\n",
    "dataTrain = []\n",
    "dataLabel = []\n",
    "temp.drop(['Date', 'stations', 'observation'], axis=1, inplace=True)\n",
    "for i in range(240): # 240 days\n",
    "    day = temp[i*features:(i+1)*features]\n",
    "    # 0-9,1-10,2-11....., 15 sets totally\n",
    "    for j in range(15):\n",
    "        everyNineHour = day.iloc[:,j:j + 9] # iloc[row,column]\n",
    "        label = day.iloc[9,j+9]\n",
    "        dataTrain.append(everyNineHour)\n",
    "        dataLabel.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda58334",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ONLY PM2.5'''\n",
    "'''--------------------Create model--------------------'''\n",
    "# Y = b + W1X1 + W2X2 + ...... + W9X9\n",
    "def linearModel():\n",
    "    learning_rate = 0.002\n",
    "    b = 0.0001\n",
    "    parameters=[0.001]*9 # all the Ws\n",
    "    loss_history=[]\n",
    "    dict={0:9,1:9,2:9,3:9,4:9,5:9,6:9,7:9,8:9,9:9}\n",
    "    iteration_count = 100  #迭代次数\n",
    "    for i in range(iteration_count):\n",
    "        # initial bias gradient and weight gradient\n",
    "        b_grad=0\n",
    "        w_grad=[0]*9\n",
    "        loss = 0\n",
    "        for k in range(3600):\n",
    "            oneDay = dataTrain[k]\n",
    "            partsum = b+parameters[0]*float(oneDay.iloc[9,0])+ parameters[1]*float(oneDay.iloc[9,1])+\\\n",
    "                      parameters[2]*float(oneDay.iloc[9,2])+ parameters[3]*float(oneDay.iloc[9,3])+ \\\n",
    "                      parameters[4]*float(oneDay.iloc[9,4])+ parameters[5]*float(oneDay.iloc[9,5])+ \\\n",
    "                      parameters[6]*float(oneDay.iloc[9,6])+ parameters[7]*float(oneDay.iloc[9,7])+ \\\n",
    "                      parameters[8]*float(oneDay.iloc[9,8])- float(dataLabel[k])\n",
    "            loss = loss + partsum * partsum\n",
    "            b_grad = b_grad + partsum\n",
    "\n",
    "            for j in range(9):\n",
    "                w_grad[j]=w_grad[j]+ partsum * float(day.iloc[dict[j],j % 9])\n",
    "\n",
    "        loss_history.append(loss/2)\n",
    "        # update b and w\n",
    "        b = b - learning_rate * (b_grad/3600)\n",
    "        for t in range(9):\n",
    "            parameters[t] = parameters[t] - learning_rate * (w_grad[t]/3600)\n",
    "\n",
    "    print(\"finish training\")\n",
    "    return b, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc48c918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce9c3f0dad40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# from model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-79dca6ef1f1b>\u001b[0m in \u001b[0;36mlinearModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# update b and w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb_grad\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('./test.csv')\n",
    "answer_data = pd.read_csv('./answer.csv')\n",
    "# print(result_data)\n",
    "del test_data[\"a\"]\n",
    "del test_data[\"b\"]\n",
    "day_data = []\n",
    "check_data = []\n",
    "items=18\n",
    "\n",
    "for i in range(int(len(test_data)/items)):\n",
    "    day = test_data[i*items:(i+1)*items] # data of a day\n",
    "    day_data.append(day)\n",
    "\n",
    "# print(result_data.iloc[239,1])\n",
    "for j in range(len(answer_data)):\n",
    "    check_data.append(answer_data.iloc[j,1])\n",
    "\n",
    "# from model:\n",
    "b, parameters = linearModel()\n",
    "\n",
    "predict=[]\n",
    "\n",
    "for i in range(len(day_data)):\n",
    "    day=day_data[i]\n",
    "    p=b+parameters[0]*float(day.iloc[8,0])+parameters[1]*float(day.iloc[8,1])+\\\n",
    "    parameters[2]*float(day.iloc[8,2])+parameters[3]*float(day.iloc[8,3])+\\\n",
    "    parameters[4]*float(day.iloc[8,4])+parameters[5]*float(day.iloc[8,5])+\\\n",
    "    parameters[6]*float(day.iloc[8,6])+parameters[7]*float(day.iloc[8,7])+\\\n",
    "    parameters[8]*float(day.iloc[8,8])\n",
    "    predict.append(p)\n",
    "\n",
    "def evaluate(test,predict):\n",
    "    sum=0\n",
    "    for i in range(len(predict)):\n",
    "        sum=sum+(float(test[i])-float(predict[i]))*(float(test[i])-float(predict[i]))\n",
    "    return sum/len(predict)\n",
    "\n",
    "print(evaluate(check_data,predict))\n",
    "print(loss_history[len(loss_history)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0dfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally\n",
    "# iteration_count = 1000  #迭代次数\n",
    "# samples = 100\n",
    "# learning_rate = 0.002\n",
    "# evaluate = 4.810371555547992e+126\n",
    "# finally loss: 2.7661168056311173e+127"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
